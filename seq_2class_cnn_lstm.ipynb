{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq_2class_cnn_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSgkMa9MAwSF",
        "colab_type": "text"
      },
      "source": [
        "The below iPython NoteBook is made for Google Collaboratory. Each part is to be run only after the preceding parts have finished running.\n",
        "\n",
        "The first part of the code shows the loading IMDB data, model creation, semi-supevised/supervised training processes. It also shows the accuracy after 10 epochs. \n",
        "\n",
        "Possible Customizations:\n",
        "The num_words, skip_words, semi-supervised to supervised learning, the percentage of samples to use for supervised learning, the model file name whenever you make a new model, and the number of CNN layers to change the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISbVmHZEuQ6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSTM and CNN for sequence classification on the IMDB dataset\n",
        "import os\n",
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Dropout\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from math import floor\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "skip_top_words = 0 # 20\n",
        "semi_supervised = True  #change to false for supervised learning\n",
        "\n",
        "\n",
        "# (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words, skip_top=skip_top_words)\n",
        "# truncate and pad input sequences\n",
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
        "\n",
        "all_data = numpy.append(X_train, X_test, axis=0)\n",
        "all_label = numpy.append(y_train, y_test, axis=0)\n",
        "print(all_data.shape, all_label.shape)\n",
        "data_len = len(all_data)\n",
        "\n",
        "if semi_supervised ==True:\n",
        "  #semi-supervised : self training\n",
        "  #partition data into labeled and unlabeled\n",
        "  print(\"Using Semi-Supervised Learning\")\n",
        "  first_part = floor(0.1*data_len)\n",
        "  second_part = floor(0.8*data_len)\n",
        "  thrid_part = floor(1*data_len)\n",
        "\n",
        "  \n",
        "else:\n",
        "  #supervised learning\n",
        "  print(\"Using Supervised Learning\")\n",
        "  use_percentage = 0.1 # adjust the float value to decide the percentage of labeled data used\n",
        "  first_part = floor(use_percentage*data_len)  \n",
        "  second_part = floor(use_percentage*data_len)\n",
        "  thrid_part = floor(1*data_len)\n",
        "\n",
        "partition_indexes = [[range(0,first_part)], [range(first_part, second_part)], [range(second_part, thrid_part)]]\n",
        "\n",
        "l_data_x = all_data[partition_indexes[0]] # labeled_data\n",
        "u_data_x = all_data[partition_indexes[1]] # unlabeled_data\n",
        "t_data_x = all_data[partition_indexes[2]] # test_data\n",
        "\n",
        "l_data_y = all_label[partition_indexes[0]] \n",
        "u_data_y = all_label[partition_indexes[1]]\n",
        "t_data_y = all_label[partition_indexes[2]]\n",
        "\n",
        "print(\"Original : Labeled : Unlabeled > \",X_train.shape, y_train.shape, l_data_x.shape, l_data_y.shape, u_data_x.shape, u_data_y.shape)\n",
        "\n",
        " \n",
        "\n",
        "model_file_name = \"best_model_4cnn_1dense_skip_model_semisupervised.hdf5\"\n",
        "times = 10\n",
        "for curr_time in range(times):\n",
        "    print(\"Iteration\", curr_time)\n",
        "    # create the model\n",
        "    path = \"/content/\" + model_file_name\n",
        "    if (os.path.exists(path)):\n",
        "      model = load_model(path)\n",
        "      print(\"model loaded from \"+path)\n",
        "      if semi_supervised == True:\n",
        "        print(\"adding unlabeled data by self-training\")\n",
        "        predicted_y = model.predict(u_data_x)\n",
        "        new_data_x = []\n",
        "        new_data_y = []\n",
        "        threshold = 0.2\n",
        "        for i,y in enumerate(predicted_y):\n",
        "          if y<threshold or y>(1.0-threshold):\n",
        "            new_data_x.append(u_data_x[i])\n",
        "            new_data_y.append(0 if y<threshold else 1)\n",
        "\n",
        "        print(\"new data added for training: \", len(new_data_y))\n",
        "        \n",
        "        if new_data_x !=[]:\n",
        "          l_data_x = numpy.append(l_data_x, numpy.asarray(new_data_x), axis=0)\n",
        "          l_data_y = numpy.append(l_data_y, numpy.asarray(new_data_y), axis=0)\n",
        "\n",
        "        # shuffle the updated data\n",
        "        indices = numpy.arange(len(l_data_x))\n",
        "        numpy.random.shuffle(indices)\n",
        "        l_data_x = l_data_x[indices]\n",
        "        l_data_y = l_data_y[indices]\n",
        "    else:\n",
        "      print(\"building a new model\")\n",
        "      embedding_vecor_length = 32\n",
        "      model = Sequential()\n",
        "      model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "      model.add(Dropout(0.2))\n",
        "      model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "      model.add(MaxPooling1D(pool_size=2))\n",
        "      model.add(Dropout(0.2))\n",
        "      model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "      model.add(MaxPooling1D(pool_size=2))\n",
        "      model.add(Dropout(0.2))\n",
        "      model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "      model.add(MaxPooling1D(pool_size=2))\n",
        "      model.add(Dropout(0.2))\n",
        "      model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "      model.add(MaxPooling1D(pool_size=2))\n",
        "      model.add(Dropout(0.2))\n",
        "      model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "      model.add(Dropout(0.2))\n",
        "      model.add(Dense(1, activation='sigmoid'))\n",
        "      model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "      print(model.summary())\n",
        "    checkpoint = ModelCheckpoint(model_file_name, monitor='loss', verbose=1, save_best_only=True, mode='auto', period=1)\n",
        "    model.fit(l_data_x, l_data_y, epochs=2, batch_size=64, callbacks=[checkpoint])\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(t_data_x, t_data_y, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "\n",
        "#/content/best_model.hdf5\n",
        "#/content/best_model_cnn.hdf5\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYhkEPpTDmp1",
        "colab_type": "text"
      },
      "source": [
        "The below code is for evaluation and in-depth understanding of the working of the above model.\n",
        "\n",
        "First, the dictionary for word to index mapping is extracted and used to print what a typical training data sample might look like and how it is interpreted by the model.\n",
        "\n",
        "Then using the same procedure, a generic test string is created and passed to model and the prediction is printed. \n",
        "\n",
        "Possible Customizations:\n",
        "The generic text string could be anything given by the user. For now, only simple format is supported, i.e. spaces before and after \".\", so that it can be marked as <UNK> and does not affect the sequence much."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz19Vg9ItYUY",
        "colab_type": "code",
        "outputId": "6314f8b6-57f4-4e98-c55d-f36168df09b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "''' For Evaluation '''\n",
        "\n",
        "NUM_WORDS=top_words # only use top 1000 words\n",
        "INDEX_FROM=3   # word index offset\n",
        "import numpy as np\n",
        "# train,test = keras.datasets.imdb.load_data(num_words=NUM_WORDS, index_from=INDEX_FROM)\n",
        "# train_x,train_y = train\n",
        "# test_x,test_y = test\n",
        "\n",
        "word_to_id = imdb.get_word_index()\n",
        "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START>\"] = 1\n",
        "word_to_id[\"<UNK>\"] = 2\n",
        "word_to_id[\"<UNUSED>\"] = 3\n",
        "\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}\n",
        "print(\"Example Training Data Sample\")\n",
        "print(' '.join(id_to_word[id] for id in X_train[0] ))\n",
        "\n",
        "# print(X_train[0])\n",
        "\n",
        "### Uncomment the below sentence to evaluate a generic positive or negative string\n",
        "\n",
        "# new_in = \"I liked the film a lot . There were some excellent scenes showing spaceflight and superheores . The actors were well suited for their roles . This movie definiltely deserves an Oscar .\"\n",
        "new_in = \"The movie was so bad I walked out of the theatre after an hour . The acting and dialogs were abysmal . There was no story to be followed . This was a waste of time .\"\n",
        "new_in = new_in.lower()\n",
        "print(new_in)\n",
        "new_in = new_in.split()  # This could be improved\n",
        "words = [w if w in word_to_id else \"<UNK>\" for w in new_in]\n",
        "# print(words)\n",
        "# index_from = INDEX_FROM  # Already added in word_to_id\n",
        "index_from = 0 # Already added in word_to_id\n",
        "#replace words by their freq + index_from\n",
        "in_vec = [word_to_id[word] + index_from for word in words]\n",
        "# print(in_vec)\n",
        "max_review_length = 500\n",
        "in_vec = [word_to_id[\"<START>\"]] + in_vec\n",
        "in_vec = [in_vec]\n",
        "\n",
        "oov_char = 2\n",
        "skip_top = skip_top_words\n",
        "num_words = top_words\n",
        "if oov_char is not None:\n",
        "  for i in range(len(in_vec)):\n",
        "    in_vec[i] = [w if (skip_top <= w < num_words) else oov_char for w in in_vec[i]]\n",
        "else:\n",
        "    in_vec = [[w for w in x if skip_top <= w < num_words] for x in in_vec]\n",
        "\n",
        "#adjust the sequence length\n",
        "new_x = np.asarray(in_vec)\n",
        "# new_x = new_x.transpose()\n",
        "new_x = sequence.pad_sequences(new_x, maxlen=max_review_length)\n",
        "# new_x = []\n",
        "# for x in in_vec:\n",
        "#   new_x.append([x])\n",
        "  \n",
        "# print(new_x)\n",
        "print(\"Prediction on Generic Test String not belonging to the  Dataset\")\n",
        "# print(new_x)  # print the new input tensor\n",
        "print(' '.join(id_to_word[id] for id in new_x[0] ))\n",
        "prediction = model.predict(new_x)\n",
        "\n",
        "print(\"Predicted value is: \" + str(prediction))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example Training Data Sample\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly <UNK> was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little <UNK> that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big <UNK> for the whole film but these children are amazing and should be <UNK> for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was <UNK> with us all\n",
            "the movie was so bad i walked out of the theatre after an hour . the acting and dialogs were abysmal . there was no story to be followed . this was a waste of time .\n",
            "Prediction on Generic Test String not belonging to the  Dataset\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> the movie was so bad i walked out of the theatre after an hour <UNK> the acting and dialogs were abysmal <UNK> there was no story to be followed <UNK> this was a waste of time <UNK>\n",
            "Predicted value is: [[1.1290014e-05]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRjEjRhO-Hr0",
        "colab_type": "text"
      },
      "source": [
        "The below code is for checking the difficult cases.\n",
        "\n",
        "Possible customizations:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuIly13SL15V",
        "colab_type": "code",
        "outputId": "d8232e3a-edcc-4da2-84f8-a0bcedce94a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "predicted_y = model.predict(t_data_x)  # calculate the predicted values on the test data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# data = {'a': np.arange(50),\n",
        "#         'c': np.random.randint(0, 50, 50),\n",
        "#         'd': np.random.randn(50)}\n",
        "# data['b'] = data['a'] + 10 * np.random.randn(50)\n",
        "# data['d'] = np.abs(data['d']) * 100\n",
        "\n",
        "start = 0\n",
        "end = 10\n",
        "data = {'a':np.arange(start, end), 'b':t_data_y[start:end]}\n",
        "\n",
        "plt.scatter('a', 'b', data=data)\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n",
        "\n",
        "data = {'a':np.arange(start, end), 'b':predicted_y[start:end]}\n",
        "\n",
        "plt.scatter('a', 'b', data=data)\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Predicted Labels')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSY37//aYm9YedY8DAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nknrOIJCknjMIJKnn/j8dXhNOU4UJlwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsZsraEMGbON",
        "colab_type": "text"
      },
      "source": [
        "The below code is to print the difficult cases.\n",
        "\n",
        "Possible customizations:\n",
        "The index of the test data to print."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C05b_xoeRJ7L",
        "colab_type": "code",
        "outputId": "1f63a034-4323-4b87-ab94-5db75d52507a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def vec2string(in_vec):\n",
        "  NUM_WORDS=top_words # only use top 1000 words\n",
        "  INDEX_FROM=3   # word index offset\n",
        "  # train,test = keras.datasets.imdb.load_data(num_words=NUM_WORDS, index_from=INDEX_FROM)\n",
        "  # train_x,train_y = train\n",
        "  # test_x,test_y = test\n",
        "\n",
        "  word_to_id = imdb.get_word_index()\n",
        "  word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
        "  word_to_id[\"<PAD>\"] = 0\n",
        "  word_to_id[\"<START>\"] = 1\n",
        "  word_to_id[\"<UNK>\"] = 2\n",
        "  word_to_id[\"<UNUSED>\"] = 3\n",
        "\n",
        "  id_to_word = {value:key for key,value in word_to_id.items()}\n",
        "  return ' '.join(id_to_word[id] for id in in_vec )\n",
        "\n",
        "index_to_study = 2  # change the index to which string you want print out based on the plots above\n",
        "difficult_str = vec2string(t_data_x[index_to_study])  \n",
        "print(difficult_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> the duke is a very silly film a dog becoming a duke but it's a very fun movie it has some of those corny <UNK> that many kids movies have but thankfully no <UNK> <UNK> jokes as so many animal movies feel compelled to have mostly it's just dogs being dogs and people being well people the <UNK> <UNK> are <UNK> and appealing the <UNK> <UNK> are ridiculous and of course the <UNK> of many jokes but there is something <UNK> about this movie for even though it is silly it's not out for every cheap laugh like home alone and others br br <UNK> simon and <UNK> do an excellent job playing black and <UNK> <UNK> who becomes the duke after his beloved owner a real duke dies for the most part they just act like dogs no ' or human like emotions and attitudes however they do stereotype <UNK> and <UNK> does fall for her just because she's a <UNK> come on these are dogs they have a different view of beauty br br overall charming fun and enjoyable\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}